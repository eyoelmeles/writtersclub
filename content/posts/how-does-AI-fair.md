---
title: "How does AI fare"
date: 2022-12-22T05:47:22.845Z
draft: false
---

## How does AI fare?

Building intelligent computers that can carry out tasks that traditionally require human intelligence is the goal of artificial intelligence (AI), a broad field of computer science. Although there are many different approaches to the interdisciplinary science of artificial intelligence (AI), advances in machine learning and deep learning are causing a paradigm change in almost every area of the tech industry.

AI is becoming more and more prevalent in daily life, from the emergence of self-driving cars to the proliferation of smart assistants like Siri and Alexa. As a result, numerous tech firms from a variety of sectors are making investments in artificial intelligence technologies.
The biggest limitation of describing AI as merely "creating machines that are intelligent" is that it fails to define AI and explain what constitutes an intelligent machine. Although there are many different approaches to the interdisciplinary science of artificial intelligence (AI), advances in machine learning and deep learning are causing a paradigm change in almost every area of the tech industry.

A 2019 research study titled "On the Measure of Intelligence" is one example of a new test that has been suggested recently and has received generally positive reviews. In the article, François Chollet, a seasoned expert in deep learning and a Google employee, makes the claim that intelligence is defined as the "pace at which a learner transforms their existing knowledge and experience into new skills at worthwhile activities that include uncertainty and adaptation." In other words, the most intelligent algorithms are able to predict what will happen in a variety of situations with only a tiny quantity of experience.
When one takes into account the computing costs and the technological data infrastructure that support artificial intelligence, putting AI into practice is a difficult and expensive endeavor. Fortunately, there have been significant advances in computing technology, as demonstrated by Moore's Law, which claims that the price of computers is cut in half while the number of transistors on a microchip double roughly every two years.

Although many experts anticipate that Moore’s Law will likely come to an end somewhere in the 2020s, this has had a big impact on present AI approaches – without it, deep learning would be out of the question, financially speaking. According to recent study, Moore's Law has actually been outpaced by AI innovation, which doubles roughly every six months as opposed to every two years.
